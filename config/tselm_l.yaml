#
# TRAIN the blind separation using the recipe provided in DASB
#

### seed ###
sampler_seed: 1234
seed: 1234

### ddp config ###
gpus: [0,1,2,3]
port: 12356

### data ###
tr_dataset: !name:dataset.TargetDMDataset ## libri speech DM dataset
  scp_path: /public/home/qinxy/zbang/data/LibriSpeech/scp/train/train_clean_100_360.pt
  epoch_num: 5_0000
  mix_length: 48080
  regi_length: 64080
cv_dataset: !name:dataset.TargetDataset
  mix_path: "/public/home/qinxy/bltang/data/LibriMix/Libri2Mix/wav16k/min/lists/test/mix.scp"
  regi_path: "/public/home/qinxy/bltang/data/LibriMix/Libri2Mix/wav16k/min/lists/test/bltang/regi.scp"
  clean_path: "/public/home/qinxy/bltang/data/LibriMix/Libri2Mix/wav16k/min/lists/test/s1.scp"
  mix_length: 48080
  regi_length: 64080
batch_size: 64
num_workers: 2
batch_size_eval: 128

### log ###
log_interval: 5


### train ###
trainer: !name:exp.tselm.trainer.Trainer
epoch: 100
find_unused: False
pre_eval: False # before training, do a pre evaluation to see if anything with the evaluation is right
best_field: error # Save the best model according to what field
best_save_type: descend #[descend, ascend] ## descend means that the the lower the value the best_field, the better it will be
max_ckpt: 1 # The maximum ckpt to keep

### optim and scheduler ###
lr: 0.00005
optim: !name:torch.optim.AdamW
  lr: !ref <lr>
  betas: (0.9, 0.98)
  eps: 1.e-8
  weight_decay: 0.01
new_bob: !new:scheduler.schedulers.NewBobScheduler
  initial_value: !ref <lr>
  annealing_factor: 0.9
  improvement_threshold: 0.0025
  patient: 1

### model ###
num_clusters: 1000
embedding_dim: 1024
d_model: 768
num_heads: 16
num_layers: 12
ssl_layers: [1, 3, 7, 12, 18, 23]

FiLM: !new:models.modules.film.FiLM
    size: !ref <embedding_dim>

cross_attention_model: !new:models.modules.transformer_encoder_cross.TransformerEncoderCross
    num_layers: 4
    d_model: !ref <embedding_dim>
    nhead: 16
    d_ffn: 1024
    dropout: 0
fusion_norm: !new:torch.nn.GroupNorm
  num_groups: 1
  num_channels: !ref <embedding_dim>
  eps: 1.e-8

hifi_gan: !new:models.hifi_gan.HiFiGAN
  model_path: /public/home/qinxy/bltang/pretrain_dasb_tokenizer/models/hifigan-wavlm-l1-3-7-12-18-23-k1000-LibriTTS

ssl_model: !new:models.wavlm.WavLM
  model_path: /public/home/qinxy/bltang/pretrain_dasb_tokenizer/models/wavlm-large

discrete_ssl: !new:models.discrete_ssl.DiscreteSSL
  ssl_model: !ref <ssl_model>
  kmeans_path: /public/home/qinxy/bltang/pretrain_dasb_tokenizer/models/SSL_Quantization/LibriSpeech-100-360-500/wavlm
  num_clusters: !ref <num_clusters>
  
attention_mlp: !new:exp.tselm.modules.AttentionMLP
  input_dim: !ref <embedding_dim>
  hidden_dim: !ref <embedding_dim>

embedding: !new:exp.tselm.modules.Discrete_EmbeddingLayer
  num_codebooks: !apply:exp.tselm.utils.get_len 
    array: !ref <ssl_layers>
  vocab_size: !ref <num_clusters>
  emb_dim: !ref <embedding_dim>
  freeze: False

head: !new:torch.nn.Linear 
  in_features: !ref <d_model>
  out_features: !apply:exp.tselm.utils.len_ 
    [1, !ref <ssl_layers>, !ref <num_clusters>]

lm_model: !new:speechbrain.lobes.models.transformer.TransformerASR.TransformerASR
    input_size: !ref <embedding_dim>
    tgt_vocab: -1
    d_model: !ref <d_model>
    nhead: !ref <num_heads>
    num_encoder_layers: !ref <num_layers>
    num_decoder_layers: 0
    d_ffn: 2048
    dropout: 0.1
    activation: !name:torch.nn.GELU
    max_length: 2000
    encoder_module: conformer
    normalize_before: True
    causal: False

model: !new:exp.tselm.model.Model
  hifi_gan: !ref <hifi_gan>
  discrete_ssl: !ref <discrete_ssl>
  ssl_layers: !ref <ssl_layers>
  attention_mlp: !ref <attention_mlp>
  lm_model: !ref <lm_model>
  embedding: !ref <embedding>
  head: !ref <head>
  vocab_size: !ref <num_clusters>
  fusion: !ref <cross_attention_model>
  film: !ref <FiLM>
  fusion_norm: !ref <fusion_norm>