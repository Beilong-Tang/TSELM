# TSELM-L Config
#
### Configuration 
#### data configuration
tr_data_scp_path: <path_to_train_100_360.pt>
cv_mix_path: <path_to_mix_clean.scp>
cv_ref_path: <path_to_aux_s1.scp>
cv_clean_path: <path_to_s1.scp>
#### pretrain model configuration
hifi_gan_path: <path_to_hifi_gan_ckpt_folder>
wavlm_path: <path_to_wavlm_ckpt_folder>
kmeans_path: <path_to_kmeans_ckpt_folder> 
##############################################

### ddp config ###
gpus: [0,1,2,3,4,5,6,7,8] ## The number of GPUS to run the experiment on 
port: 12355 ## The port number for DDP

########################################
### seed ###
sampler_seed: 1234 # This field is not used because we use dynamic mixing instead of sampler
seed: 1234 # The training and accessing data seed for reproductivity


### data ###
tr_dataset: !name:dataset.TargetDMDataset ## libri speech DM dataset
  scp_path: !ref <tr_data_scp_path>
  epoch_num: 5_0000 # How many data to be considered as one epoch
  mix_length: 48080 # The mixture audio length (3.05 s x 16000)
  regi_length: 64080 # The reference audio length (4.05 s x 16000)
cv_dataset: !name:dataset.TargetDataset
  mix_path: !ref <cv_mix_path>
  regi_path: !ref <cv_ref_path>
  clean_path: !ref <cv_clean_path>
  mix_length: 48080
  regi_length: 64080
batch_size: 128 # The total batch size
num_workers: 2 # Data loader num workers
batch_size_eval: 256 # The total evaluation batch size

### log ###
log_interval: 5 # The interval for logging 


### train ###
trainer: !name:exp.tselm.trainer.Trainer
epoch: 100 # The total Epoch number
find_unused: False # Specifies the DDP find_unused field
pre_eval: False # before training, do a pre evaluation to see if anything with the evaluation is right
best_field: error # Save the best model according to this field
best_save_type: descend #[descend, ascend] ## descend means that the the lower the value the best_field, the better it will be
max_ckpt: 1 # The maximum number of checkpoints to keep in the ckpt folder

### optim and scheduler ###
lr: 0.00005
optim: !name:torch.optim.AdamW
  lr: !ref <lr>
  betas: (0.9, 0.98)
  eps: 1.e-8
  weight_decay: 0.01
new_bob: !new:scheduler.schedulers.NewBobScheduler
  initial_value: !ref <lr>
  annealing_factor: 0.9
  improvement_threshold: 0.0025
  patient: 1

### model specific ###
num_clusters: 1000
embedding_dim: 1024
d_model: 768
num_heads: 16
num_layers: 12
ssl_layers: [1, 3, 7, 12, 18, 23]

FiLM: !new:models.modules.film.FiLM
    size: !ref <embedding_dim>

cross_attention_model: !new:models.modules.transformer_encoder_cross.TransformerEncoderCross
    num_layers: 4
    d_model: !ref <embedding_dim>
    nhead: 16
    d_ffn: 1024
    dropout: 0
fusion_norm: !new:torch.nn.GroupNorm
  num_groups: 1
  num_channels: !ref <embedding_dim>
  eps: 1.e-8

hifi_gan: !new:models.hifi_gan.HiFiGAN
  model_path: !ref <hifi_gan_path>

ssl_model: !new:models.wavlm.WavLM
  model_path: !ref <wavlm_path>

discrete_ssl: !new:models.discrete_ssl.DiscreteSSL
  ssl_model: !ref <ssl_model>
  kmeans_path: !ref <kmeans_path>
  num_clusters: !ref <num_clusters>
  
attention_mlp: !new:exp.tselm.modules.AttentionMLP
  input_dim: !ref <embedding_dim>
  hidden_dim: !ref <embedding_dim>

embedding: !new:exp.tselm.modules.Discrete_EmbeddingLayer
  num_codebooks: !apply:exp.tselm.utils.get_len 
    array: !ref <ssl_layers>
  vocab_size: !ref <num_clusters>
  emb_dim: !ref <embedding_dim>
  freeze: False

head: !new:torch.nn.Linear 
  in_features: !ref <d_model>
  out_features: !apply:exp.tselm.utils.len_ 
    [!ref <ssl_layers>, !ref <num_clusters>]

lm_model: !new:speechbrain.lobes.models.transformer.TransformerASR.TransformerASR
    input_size: !ref <embedding_dim>
    tgt_vocab: -1
    d_model: !ref <d_model>
    nhead: !ref <num_heads>
    num_encoder_layers: !ref <num_layers>
    num_decoder_layers: 0
    d_ffn: 2048
    dropout: 0.1
    activation: !name:torch.nn.GELU
    max_length: 2000
    encoder_module: conformer
    normalize_before: True
    causal: False

model: !new:exp.tselm.model.Model
  hifi_gan: !ref <hifi_gan>
  discrete_ssl: !ref <discrete_ssl>
  ssl_layers: !ref <ssl_layers>
  attention_mlp: !ref <attention_mlp>
  lm_model: !ref <lm_model>
  embedding: !ref <embedding>
  head: !ref <head>
  vocab_size: !ref <num_clusters>
  fusion: !ref <cross_attention_model>
  film: !ref <FiLM>
  fusion_norm: !ref <fusion_norm>